{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read datasets from all waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor dataset of wave 1 was loaded successfully\n",
      "anchor dataset of wave 2 was loaded successfully\n",
      "anchor dataset of wave 3 was loaded successfully\n",
      "anchor dataset of wave 4 was loaded successfully\n",
      "anchor dataset of wave 5 was loaded successfully\n",
      "anchor dataset of wave 6 was loaded successfully\n",
      "anchor dataset of wave 7 was loaded successfully\n",
      "anchor dataset of wave 8 was loaded successfully\n",
      "anchor dataset of wave 9 was loaded successfully\n",
      "anchor dataset of wave 10 was loaded successfully\n",
      "anchor dataset of wave 11 was loaded successfully\n"
     ]
    }
   ],
   "source": [
    "data_anchor = {}\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,11]:\n",
    "    data_anchor[\"wave\"+str(i)] = pd.read_stata('../../data/pairfam_v11/Data/Stata/anchor'+str(i)+'.dta')\n",
    "    print('anchor dataset of wave '+str(i)+' was loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partner dataset of wave 1 was loaded successfully\n",
      "partner dataset of wave 2 was loaded successfully\n",
      "partner dataset of wave 3 was loaded successfully\n",
      "partner dataset of wave 4 was loaded successfully\n",
      "partner dataset of wave 5 was loaded successfully\n",
      "partner dataset of wave 6 was loaded successfully\n",
      "partner dataset of wave 7 was loaded successfully\n",
      "partner dataset of wave 8 was loaded successfully\n",
      "partner dataset of wave 9 was loaded successfully\n",
      "partner dataset of wave 10 was loaded successfully\n",
      "partner dataset of wave 11 was loaded successfully\n"
     ]
    }
   ],
   "source": [
    "data_partner = {}\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,11]:\n",
    "    data_partner[\"wave\"+str(i)] = pd.read_stata('../../data/pairfam_v11/Data/Stata/partner'+str(i)+'.dta')\n",
    "    print('partner dataset of wave '+str(i)+' was loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a meta data set with all subjects (anchors and partners combined):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_values(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype('str').str.extract(r\"([-+]?\\d*\\.*\\d+|\\d+)\",expand=False).astype('float')\n",
    "        df[col] = df[col]\n",
    "        df.loc[df[col]<0,[col]] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_singles(df):\n",
    "    df = df[df['pid']>=0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_anchor = data_anchor['wave1'].loc[:, ['id', 'pid', 'original_doby', 'sex_gen']]\n",
    "subjects_anchor.rename(columns={'original_doby': 'doby', 'sex_gen': 'gen'}, inplace=True)\n",
    "subjects_anchor['subj_type'] = 'anchor'\n",
    "\n",
    "subjects_partner = data_partner['wave1'].loc[:, ['id', 'pid', 'pdoby', 'psex']]\n",
    "subjects_partner.rename(columns={'id': 'pid', 'pid': 'id', 'pdoby': 'doby', 'psex': 'gen'}, inplace=True)\n",
    "subjects_partner['subj_type'] = 'partner'\n",
    "\n",
    "subjects = pd.concat([subjects_anchor, subjects_partner])\n",
    "subjects = exclude_singles(subjects)\n",
    "subjects.loc[:, ['doby', 'gen']] = recode_values(subjects.loc[:, ['doby', 'gen']])\n",
    "subjects.drop(['pid'], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doby</th>\n",
       "      <th>gen</th>\n",
       "      <th>subj_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309000</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>907000</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1028000</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1299000</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300000</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>748577101</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>748755101</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>748982101</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>749211101</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>749432101</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>partner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10977 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    doby  gen subj_type\n",
       "2        309000  1981.0  2.0    anchor\n",
       "5        907000  1981.0  2.0    anchor\n",
       "7       1028000  1983.0  2.0    anchor\n",
       "12      1299000  1972.0  2.0    anchor\n",
       "13      1300000  1973.0  1.0    anchor\n",
       "...         ...     ...  ...       ...\n",
       "3738  748577101  1970.0  1.0   partner\n",
       "3739  748755101  1969.0  1.0   partner\n",
       "3740  748982101  1982.0  1.0   partner\n",
       "3741  749211101  1970.0  2.0   partner\n",
       "3742  749432101  1986.0  2.0   partner\n",
       "\n",
       "[10977 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create subsets for each wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {'per1i2':        {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'Sometimes I believe that I am worthless'}, \n",
    "             'per1i7':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'I like myself just the way I am'}, \n",
    "             'per1i13':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'All in all, I am pleased with myself'},                      \n",
    "             'pa18i2':        {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'Sometimes I am afraid that partner would rather spend time with others'}, \n",
    "             'pa18i7':        {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'I have the feeling that I like partner more than he/she likes me'}, \n",
    "             'pa18i10':       {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'Sometimes not sure if partner enjoys being with me as much as I'}, \n",
    "             'pa18i12':       {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'Afraid partner will think I am silly/stupid if I make a mistake'}, \n",
    "             'pa18i15':       {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'When I disappoint/annoy partner, I am afraid he/she will not like me'}, \n",
    "             'per1i6':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'I feel lonely'}, \n",
    "             'sat6':          {'max': 10, 'min': 0, 'inverted': 'no',  'desc': 'General satisfaction with life'},\n",
    "             'atts':          {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Attachment: Model of self'},\n",
    "             'atto':          {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Attachment: Model of others'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {'bce1i5':        {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'VOP+: Affection and feeling of security in relationship'}, \n",
    "             'bce1i6':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'VOP+: Freedom to follow own interests by relationship '}, \n",
    "             'bce1i12':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'VOP+: Pursue own interests in partnership'}, \n",
    "             'bce1i10':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'VOP-: Constrained by partner'}, \n",
    "             'per1i2':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Sometimes I believe that I am worthless'}, \n",
    "             'per1i7':        {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'I like myself just the way I am'}, \n",
    "             'per1i13':       {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'All in all, I am pleased with myself'},                      \n",
    "             'pa17i1':        {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'Frequency: Telling partner what you are thinking'}, \n",
    "             'pa17i8':        {'max': 5,  'min': 1, 'inverted': 'yes', 'desc': 'Frequency: Sharing secrets and private feelings with partner'}, \n",
    "             'pa18i2':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Sometimes I am afraid that partner would rather spend time with others'}, \n",
    "             'pa18i4':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Partner clings to me so much that I feel like I am suffocating'}, \n",
    "             'pa18i7':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'I have the feeling that I like partner more than he/she likes me'}, \n",
    "             'pa18i10':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Sometimes not sure if partner enjoys being with me as much as I'}, \n",
    "             'pa18i12':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Afraid partner will think I am silly/stupid if I make a mistake'}, \n",
    "             'pa18i14':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Partner clings to me so tightly that I cannot do what I want '}, \n",
    "             'pa18i15':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'When I disappoint/annoy partner, I am afraid he/she will not like me'}, \n",
    "             'per1i6':        {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'I feel lonely'}, \n",
    "             'sat6':          {'max': 10, 'min': 0, 'inverted': 'no',  'desc': 'General satisfaction with life'},\n",
    "             'att_anx':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Attachment Anxiety'},\n",
    "             'att_avd':       {'max': 5,  'min': 1, 'inverted': 'no',  'desc': 'Attachment Avoidance'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, add_prfx='', rem_prfx='', add_sffx=''):\n",
    "    df = df.copy()\n",
    "    for var in variables:\n",
    "        df.rename(columns = {rem_prfx+var:     add_prfx+var+add_sffx, \n",
    "                             rem_prfx+'p'+var: add_prfx+'p'+var+add_sffx}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns(df, variables):\n",
    "    variables_avail = list(set(df.columns).intersection(variables))\n",
    "    variables_avail.append('id')\n",
    "    variables_avail.append('pid')\n",
    "    df = df.loc[:, variables_avail]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_scales(df, variables):\n",
    "    for col in df:\n",
    "        if(col in variables and variables[col]['inverted'] == 'yes'):\n",
    "            df[col].mask(df[col]>=0, variables[col]['max']-df[col]+variables[col]['min'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_variables(df):\n",
    "    \n",
    "    # Calculate measure for 'model of self'\n",
    "    if 'per1i2' in df.columns:\n",
    "        df['atts'] = df[['per1i2', 'per1i7', 'per1i13']].mean(axis=1)\n",
    "    df.loc[((df['per1i2']==-2) | (df['per1i7']==-2) | (df['per1i13']==-2)),['atts']] = np.nan    \n",
    "        \n",
    "    if 'pa18i2' in df.columns:\n",
    "        df['atto'] = df[['pa18i2', 'pa18i7', 'pa18i10', 'pa18i12', 'pa18i15']].mean(axis=1) # column for model of self\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_variables(df):\n",
    "    \n",
    "    # Calculate measure for 'attachment anxiety\n",
    "    if 'per1i2' in df.columns:\n",
    "        df['att_anx'] = df[['per1i2', 'per1i7', 'per1i13', 'pa18i7', 'pa18i10', 'pa18i2', 'pa18i12', 'pa18i15']].mean(axis=1)\n",
    "    df.loc[((df['per1i2']==-2) | (df['per1i7']==-2) | (df['per1i13']==-2)),['atts']] = np.nan    \n",
    "     \n",
    "    # Calculate measure for 'attachment avoidance'\n",
    "    if 'pa18i4' in df.columns:\n",
    "        df['att_avd'] = df[['bce1i5', 'bce1i6', 'bce1i12', 'bce1i10', 'pa17i1', 'pa17i8', 'pa18i4', 'pa18i14']].mean(axis=1) \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_anchor_partner(df_anchor, df_partner):\n",
    "    df = df_anchor.merge(df_partner, left_on='pid', right_on='id', how='left', suffixes=['', '_y'])\n",
    "    df.drop(['id_y', 'pid_y', 'pageExact', 'page', 'pint'], axis=1, inplace=True, errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = {}\n",
    "\n",
    "for i in range(1,12):\n",
    "    \n",
    "    # Process anchor datasets\n",
    "    df_a = data_anchor[\"wave\"+str(i)]\n",
    "    df_a = extract_columns(df_a, variables) # Keep only the relevant columns\n",
    "    df_a = recode_values(df_a) # Recodes the values (\"1\" instead of \"1 Trifft Ã¼berhaupt nicht zu\")\n",
    "    df_a = invert_scales(df_a, variables)\n",
    "    df_a = combine_variables(df_a) # Creates combined measures for attachment model of self and model of others\n",
    "\n",
    "    # Process partner datasets \n",
    "    df_p = data_partner[\"wave\"+str(i)]\n",
    "    df_p = rename_columns(df_p, rem_prfx='p') # Removes the 'p' before the field names\n",
    "    df_p = extract_columns(df_p, variables) # Keep only the relevant columns\n",
    "    df_p = recode_values(df_p) # Recodes the values (\"1\" instead of \"1 Trifft Ã¼berhaupt nicht zu\")\n",
    "    df_p = invert_scales(df_p, variables)\n",
    "    df_p = combine_variables(df_p) # Creates combined measures for attachment model of self and model of others\n",
    "    df_p = df_p.rename(columns={'pid': 'id', 'id': 'pid'}) # switch IDs, because identifer of partner subjects is pid and not id\n",
    "\n",
    "    df1 = join_anchor_partner(df_a, rename_columns(df_p, add_prfx='p'))\n",
    "    df2 = join_anchor_partner(df_p, rename_columns(df_a, add_prfx='p'))\n",
    "\n",
    "    df = pd.concat([df1, df2])\n",
    "    \n",
    "    subsets[\"wave\"+str(i)] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all subsets into one dataframe with a Long Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['patt_avd', 'att_avd', 'att_anx', 'patt_anx'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b92321018b01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Normalize variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvar\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mdf_long\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_long\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdf_long\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdf_long\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['patt_avd', 'att_avd', 'att_anx', 'patt_anx'] not in index\""
     ]
    }
   ],
   "source": [
    "df_long = {}\n",
    "\n",
    "# Calculate age\n",
    "for i in range(1,12):\n",
    "    df_temp = subjects.copy().merge(subsets['wave'+str(i)], how='left', on='id')\n",
    "    df_temp['age'] = 2009-df_temp['doby']+i\n",
    "    df_temp['wave'] = i\n",
    "    df_long['wave'+str(i)] = df_temp\n",
    "\n",
    "# Concat subsets\n",
    "df_long = pd.concat([df_long['wave1'], df_long['wave2'], df_long['wave3'],\n",
    "                     df_long['wave4'], df_long['wave5'], df_long['wave6'],\n",
    "                     df_long['wave7'], df_long['wave8'], df_long['wave9'],\n",
    "                     df_long['wave10'], df_long['wave11']])\n",
    "\n",
    "# Drop NANs\n",
    "#df_long.drop(df_long[df_long['age'].isnull()].index, inplace=True)\n",
    "df_long.dropna(thresh=len(df_long.columns)-len(variables)*2, inplace=True) # thresh = number of non-variable columns\n",
    "\n",
    "# Drop time points when subjects wasn't in a relationship\n",
    "df.dropna(subset=['pid'], inplace=True)\n",
    "\n",
    "# Normalize variables\n",
    "columns = ['p'+var for var in variables] + list(variables)\n",
    "df_long[columns] = (df_long[columns]-df_long[columns].mean()) / df_long[columns].std()\n",
    "\n",
    "# Export\n",
    "df_long.to_csv('../../data/samples/data6.csv', index=False)\n",
    "df_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze descriptives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_type</th>\n",
       "      <th>m</th>\n",
       "      <th>sd</th>\n",
       "      <th>corr</th>\n",
       "      <th>wave1</th>\n",
       "      <th>wave2</th>\n",
       "      <th>wave3</th>\n",
       "      <th>wave4</th>\n",
       "      <th>wave5</th>\n",
       "      <th>wave6</th>\n",
       "      <th>wave7</th>\n",
       "      <th>wave8</th>\n",
       "      <th>wave9</th>\n",
       "      <th>wave10</th>\n",
       "      <th>wave11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sat6</th>\n",
       "      <td>anchor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7231</td>\n",
       "      <td>5076</td>\n",
       "      <td>4376</td>\n",
       "      <td>3954</td>\n",
       "      <td>3559</td>\n",
       "      <td>3230</td>\n",
       "      <td>2931</td>\n",
       "      <td>2712</td>\n",
       "      <td>2542</td>\n",
       "      <td>2380</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per1i6</th>\n",
       "      <td>anchor</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.015695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3934</td>\n",
       "      <td>3549</td>\n",
       "      <td>0</td>\n",
       "      <td>2916</td>\n",
       "      <td>2712</td>\n",
       "      <td>2537</td>\n",
       "      <td>2371</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atts</th>\n",
       "      <td>anchor</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.001066</td>\n",
       "      <td>0.821334</td>\n",
       "      <td>7213</td>\n",
       "      <td>5061</td>\n",
       "      <td>4363</td>\n",
       "      <td>3944</td>\n",
       "      <td>3553</td>\n",
       "      <td>3225</td>\n",
       "      <td>2918</td>\n",
       "      <td>2714</td>\n",
       "      <td>2537</td>\n",
       "      <td>2372</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atto</th>\n",
       "      <td>anchor</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.712530</td>\n",
       "      <td>7166</td>\n",
       "      <td>2156</td>\n",
       "      <td>3812</td>\n",
       "      <td>0</td>\n",
       "      <td>3128</td>\n",
       "      <td>0</td>\n",
       "      <td>2590</td>\n",
       "      <td>0</td>\n",
       "      <td>2239</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psat6</th>\n",
       "      <td>anchor</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.065495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3668</td>\n",
       "      <td>2446</td>\n",
       "      <td>2084</td>\n",
       "      <td>1878</td>\n",
       "      <td>1708</td>\n",
       "      <td>1589</td>\n",
       "      <td>1437</td>\n",
       "      <td>1358</td>\n",
       "      <td>1231</td>\n",
       "      <td>1123</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pper1i6</th>\n",
       "      <td>anchor</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.027463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3660</td>\n",
       "      <td>0</td>\n",
       "      <td>2087</td>\n",
       "      <td>1860</td>\n",
       "      <td>1710</td>\n",
       "      <td>1571</td>\n",
       "      <td>372</td>\n",
       "      <td>1344</td>\n",
       "      <td>335</td>\n",
       "      <td>1111</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patts</th>\n",
       "      <td>anchor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.021127</td>\n",
       "      <td>0.820607</td>\n",
       "      <td>3696</td>\n",
       "      <td>2425</td>\n",
       "      <td>2094</td>\n",
       "      <td>1877</td>\n",
       "      <td>1715</td>\n",
       "      <td>1588</td>\n",
       "      <td>374</td>\n",
       "      <td>1361</td>\n",
       "      <td>337</td>\n",
       "      <td>1119</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patto</th>\n",
       "      <td>anchor</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.046002</td>\n",
       "      <td>0.723189</td>\n",
       "      <td>3699</td>\n",
       "      <td>0</td>\n",
       "      <td>2094</td>\n",
       "      <td>0</td>\n",
       "      <td>1727</td>\n",
       "      <td>0</td>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat6</th>\n",
       "      <td>partner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3668</td>\n",
       "      <td>2039</td>\n",
       "      <td>1645</td>\n",
       "      <td>1440</td>\n",
       "      <td>1260</td>\n",
       "      <td>1149</td>\n",
       "      <td>1029</td>\n",
       "      <td>917</td>\n",
       "      <td>825</td>\n",
       "      <td>754</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per1i6</th>\n",
       "      <td>partner</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.956276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3660</td>\n",
       "      <td>0</td>\n",
       "      <td>1645</td>\n",
       "      <td>1426</td>\n",
       "      <td>1261</td>\n",
       "      <td>1142</td>\n",
       "      <td>206</td>\n",
       "      <td>918</td>\n",
       "      <td>185</td>\n",
       "      <td>746</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atts</th>\n",
       "      <td>partner</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.996814</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>3696</td>\n",
       "      <td>2025</td>\n",
       "      <td>1649</td>\n",
       "      <td>1438</td>\n",
       "      <td>1265</td>\n",
       "      <td>1148</td>\n",
       "      <td>207</td>\n",
       "      <td>922</td>\n",
       "      <td>185</td>\n",
       "      <td>749</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atto</th>\n",
       "      <td>partner</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.028093</td>\n",
       "      <td>0.723324</td>\n",
       "      <td>3699</td>\n",
       "      <td>0</td>\n",
       "      <td>1649</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>0</td>\n",
       "      <td>1034</td>\n",
       "      <td>0</td>\n",
       "      <td>827</td>\n",
       "      <td>0</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psat6</th>\n",
       "      <td>partner</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.906728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3743</td>\n",
       "      <td>2052</td>\n",
       "      <td>1652</td>\n",
       "      <td>1444</td>\n",
       "      <td>1270</td>\n",
       "      <td>1154</td>\n",
       "      <td>1035</td>\n",
       "      <td>924</td>\n",
       "      <td>831</td>\n",
       "      <td>757</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pper1i6</th>\n",
       "      <td>partner</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.960862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>1268</td>\n",
       "      <td>0</td>\n",
       "      <td>1031</td>\n",
       "      <td>924</td>\n",
       "      <td>829</td>\n",
       "      <td>755</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patts</th>\n",
       "      <td>partner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976322</td>\n",
       "      <td>0.810090</td>\n",
       "      <td>3739</td>\n",
       "      <td>2047</td>\n",
       "      <td>1651</td>\n",
       "      <td>1442</td>\n",
       "      <td>1268</td>\n",
       "      <td>1153</td>\n",
       "      <td>1032</td>\n",
       "      <td>925</td>\n",
       "      <td>829</td>\n",
       "      <td>757</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patto</th>\n",
       "      <td>partner</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.940321</td>\n",
       "      <td>0.702140</td>\n",
       "      <td>3731</td>\n",
       "      <td>814</td>\n",
       "      <td>1652</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>0</td>\n",
       "      <td>1034</td>\n",
       "      <td>0</td>\n",
       "      <td>830</td>\n",
       "      <td>0</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subj_type    m        sd      corr wave1 wave2 wave3 wave4 wave5  \\\n",
       "sat6       anchor  0.0  0.971583       NaN  7231  5076  4376  3954  3559   \n",
       "per1i6     anchor -0.0  1.015695       NaN  7203     0     0  3934  3549   \n",
       "atts       anchor -0.0  1.001066  0.821334  7213  5061  4363  3944  3553   \n",
       "atto       anchor -0.0  0.988507  0.712530  7166  2156  3812     0  3128   \n",
       "psat6      anchor -0.0  1.065495       NaN  3668  2446  2084  1878  1708   \n",
       "pper1i6    anchor -0.0  1.027463       NaN  3660     0  2087  1860  1710   \n",
       "patts      anchor  0.0  1.021127  0.820607  3696  2425  2094  1877  1715   \n",
       "patto      anchor -0.0  1.046002  0.723189  3699     0  2094     0  1727   \n",
       "sat6      partner  0.0  1.069616       NaN  3668  2039  1645  1440  1260   \n",
       "per1i6    partner -0.0  0.956276       NaN  3660     0  1645  1426  1261   \n",
       "atts      partner -0.0  0.996814  0.818536  3696  2025  1649  1438  1265   \n",
       "atto      partner -0.0  1.028093  0.723324  3699     0  1649     0  1270   \n",
       "psat6     partner -0.0  0.906728       NaN  3743  2052  1652  1444  1270   \n",
       "pper1i6   partner -0.0  0.960862       NaN  3736     0     0  1439  1268   \n",
       "patts     partner  0.0  0.976322  0.810090  3739  2047  1651  1442  1268   \n",
       "patto     partner -0.0  0.940321  0.702140  3731   814  1652     0  1270   \n",
       "\n",
       "        wave6 wave7 wave8 wave9 wave10 wave11  \n",
       "sat6     3230  2931  2712  2542   2380   1990  \n",
       "per1i6      0  2916  2712  2537   2371   1983  \n",
       "atts     3225  2918  2714  2537   2372   1983  \n",
       "atto        0  2590     0  2239      0   1986  \n",
       "psat6    1589  1437  1358  1231   1123   1056  \n",
       "pper1i6  1571   372  1344   335   1111     76  \n",
       "patts    1588   374  1361   337   1119     75  \n",
       "patto       0  1444     0  1234      0   1060  \n",
       "sat6     1149  1029   917   825    754    703  \n",
       "per1i6   1142   206   918   185    746     15  \n",
       "atts     1148   207   922   185    749     14  \n",
       "atto        0  1034     0   827      0    707  \n",
       "psat6    1154  1035   924   831    757    708  \n",
       "pper1i6     0  1031   924   829    755    707  \n",
       "patts    1153  1032   925   829    757    707  \n",
       "patto       0  1034     0   830      0    708  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptives = pd.DataFrame(columns=['subj_type', 'm', 'sd', 'corr', 'wave1', 'wave2', 'wave3', 'wave4', 'wave5', 'wave6', 'wave7', 'wave8', 'wave9', 'wave10', 'wave11'])\n",
    "\n",
    "for subj_type in ('anchor', 'partner'):\n",
    "    temp = df_long[df_long['subj_type'] == subj_type]\n",
    "    for var in df_long.columns:\n",
    "        if var in variables or var[1:] in variables:\n",
    "            N = temp[[var, 'wave']].groupby('wave').count().T.add_prefix('wave')\n",
    "            m = np.round(df_long[var].mean(),4)\n",
    "            sd = temp[var].std()\n",
    "            if var=='atts':    corr = temp[['atts', 'per1i2', 'per1i7', 'per1i13']].corr()['atts'][1:].mean()\n",
    "            elif var=='atto':  corr = temp[['atto', 'pa18i2', 'pa18i7', 'pa18i10', 'pa18i12', 'pa18i15']].corr()['atto'][1:].mean()\n",
    "            elif var=='patts': corr = temp[['patts', 'pper1i2', 'pper1i7', 'pper1i13']].corr()['patts'][1:].mean()\n",
    "            elif var=='patto': corr = temp[['patto', 'ppa18i2', 'ppa18i7', 'ppa18i10', 'ppa18i12', 'ppa18i15']].corr()['patto'][1:].mean()\n",
    "            else:              corr = np.nan\n",
    "            descriptives = descriptives.append(N.join(pd.DataFrame({'subj_type': subj_type, 'm': m, 'sd': sd, 'corr': corr}, index=[var])))   \n",
    "\n",
    "descriptives[descriptives.index.isin(['sat6', 'per1i6', 'atto', 'atts', 'psat6', 'pper1i6', 'patto', 'patts'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Wide Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per1i6_T0</th>\n",
       "      <th>per1i6_T1</th>\n",
       "      <th>per1i6_T2</th>\n",
       "      <th>per1i6_T3</th>\n",
       "      <th>per1i6_T4</th>\n",
       "      <th>per1i6_T5</th>\n",
       "      <th>per1i6_T6</th>\n",
       "      <th>per1i6_T7</th>\n",
       "      <th>per1i6_T8</th>\n",
       "      <th>per1i6_T9</th>\n",
       "      <th>...</th>\n",
       "      <th>dT1</th>\n",
       "      <th>dT2</th>\n",
       "      <th>dT3</th>\n",
       "      <th>dT4</th>\n",
       "      <th>dT5</th>\n",
       "      <th>dT6</th>\n",
       "      <th>dT7</th>\n",
       "      <th>dT8</th>\n",
       "      <th>dT9</th>\n",
       "      <th>dT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10973</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10974</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10977 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       per1i6_T0  per1i6_T1  per1i6_T2  per1i6_T3  per1i6_T4  per1i6_T5  \\\n",
       "0            1.0        NaN        NaN        NaN        NaN        NaN   \n",
       "1            2.0        NaN        NaN        1.0        1.0        NaN   \n",
       "2            2.0        NaN        NaN        3.0        2.0        NaN   \n",
       "3            1.0        NaN        NaN        NaN        NaN        NaN   \n",
       "4            1.0        NaN        NaN        3.0        3.0        NaN   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "10972        1.0        NaN        NaN        NaN        3.0        NaN   \n",
       "10973        1.0        NaN        1.0        1.0        1.0        2.0   \n",
       "10974        5.0        NaN        NaN        NaN        NaN        NaN   \n",
       "10975        3.0        NaN        NaN        NaN        NaN        NaN   \n",
       "10976        2.0        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "       per1i6_T6  per1i6_T7  per1i6_T8  per1i6_T9  ...  dT1  dT2  dT3  dT4  \\\n",
       "0            NaN        NaN        NaN        NaN  ...    1    1    1    1   \n",
       "1            1.0        2.0        5.0        5.0  ...    1    1    1    1   \n",
       "2            4.0        2.0        2.0        2.0  ...    1    1    1    1   \n",
       "3            NaN        NaN        NaN        NaN  ...    1    1    1    1   \n",
       "4            1.0        1.0        2.0        2.0  ...    1    1    1    1   \n",
       "...          ...        ...        ...        ...  ...  ...  ...  ...  ...   \n",
       "10972        NaN        NaN        NaN        NaN  ...    1    1    1    1   \n",
       "10973        NaN        1.0        NaN        NaN  ...    1    1    1    1   \n",
       "10974        NaN        NaN        NaN        NaN  ...    1    1    1    1   \n",
       "10975        NaN        NaN        NaN        NaN  ...    1    1    1    1   \n",
       "10976        NaN        NaN        NaN        NaN  ...    1    1    1    1   \n",
       "\n",
       "       dT5  dT6  dT7  dT8  dT9  dT10  \n",
       "0        1    1    1    1    1     1  \n",
       "1        1    1    1    1    1     1  \n",
       "2        1    1    1    1    1     1  \n",
       "3        1    1    1    1    1     1  \n",
       "4        1    1    1    1    1     1  \n",
       "...    ...  ...  ...  ...  ...   ...  \n",
       "10972    1    1    1    1    1     1  \n",
       "10973    1    1    1    1    1     1  \n",
       "10974    1    1    1    1    1     1  \n",
       "10975    1    1    1    1    1     1  \n",
       "10976    1    1    1    1    1     1  \n",
       "\n",
       "[10977 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide = subjects.copy()\n",
    "\n",
    "for i in range(0,11):\n",
    "    df_temp = subsets[\"wave\"+str(i+1)].copy()\n",
    "    df_temp = rename_columns(df_temp, add_sffx='_T'+str(i))\n",
    "    df_wide = df_wide.merge(df_temp, how='left', on='id')\n",
    "\n",
    "# Keep only the variables relevant for the export\n",
    "cols_rel = []\n",
    "for variable in variables:\n",
    "    if variables[variable]['export'] == 'yes':\n",
    "        for i in range(0,11):\n",
    "            var_name = variable+'_T'+str(i)\n",
    "            cols_rel.append(var_name)\n",
    "            if var_name not in df_wide.columns:\n",
    "                df_wide[var_name] = np.nan          \n",
    "df_wide = df_wide.loc[:, cols_rel]\n",
    "\n",
    "# Add df columns\n",
    "for i in range(1,11):\n",
    "    df_wide['dT'+str(i)] = 1\n",
    "\n",
    "        \n",
    "# Export\n",
    "df_wide.to_csv('../../data/samples/sample_wide.csv', index=False)\n",
    "df_wide.head(1000).to_csv('../../data/samples/sample_wide_small.csv', index=False)\n",
    "df_wide.head(100).to_csv('../../data/samples/sample_wide_extrasmall.csv', index=False)\n",
    "\n",
    "df_wide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
