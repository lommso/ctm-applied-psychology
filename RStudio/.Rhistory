for (j in 1:Tpoints){
Mvalues[((n.latent*Tpoints+1)+j*n.manifest-n.manifest):((n.latent*Tpoints)+j*n.manifest), 1] <- manifestM
}
Mfree <- ((Mvalues != 0) & (Mvalues != 1) & is.na(Mvalues)==F)
CINTfree <- ((CINT!= 0))
Mlabels <- matrix(,nrow=(n.manifest*Tpoints+n.latent*Tpoints), ncol=1)
for (i in 1:(Tpoints-1)){
M_labels <- matrix((paste("intd", i, sep = "")), nrow=n.latent, ncol=1, byrow=TRUE)
for(j in 1:n.latent){
M_labels [j,1] = paste(M_labels[j,1], "[",j,",",1,"]",sep="")
}
Mlabels[(1+i*n.latent):(n.latent+i*n.latent), 1] <- M_labels
}
Mlabels[1:n.latent, 1] <- matrix((paste("m", 1:n.latent, sep = "")), nrow=n.latent, ncol=1, byrow=TRUE)
for (j in 1:Tpoints){
Mlabels[((1+n.latent*Tpoints-n.manifest)+j*n.manifest):(n.latent*Tpoints+j*n.manifest), 1] <- NA
}
###################################
### Remaining labels for Output ###
###################################
CINTlabels 	<- paste("cint",1:n.latent,sep="")
DRIFTlabels 	<- matrix(,n.latent,n.latent)
for (i in 1:n.latent){
for (j in 1:n.latent){
DRIFTlabels[i,j] = paste("F",i,j,sep="")
}
}
Qlabels 	<- matrix(,n.latent,n.latent)
for (i in 1:n.latent){
for (j in i:n.latent){
Qlabels[j,i] = paste("q",i,j,sep="")
}
Qlabels[i,j] <- Qlabels[j,i]
}
##################
##################
### RUN OPENMX ###
##################
##################
colnames(data)=Fnamesx	# rename columns of dataset
model=mxModel("EDM", type="RAM",
mxData(observed=data, type="raw"),
mxMatrix(type="Full", labels=DRIFTlabels, values=DRIFT, byrow=TRUE, free=DRIFTfree, name="DRIFT"),
mxMatrix(type="Full", labels=CINTlabels, values=CINT, free=CINTfree, name="CINT"),
mxMatrix(type="Full", labels=Qlabels, values=Q, byrow=TRUE, free=Qfree, name="Q"),
mxMatrix(type="Iden", nrow=n.latent, ncol=n.latent, free=FALSE, name="II"),
mxMatrix(
values=Avalues,
free=Afree,
labels=Alabels,
name="A"),
mxMatrix(
values=Svalues,
free=Sfree,
labels=Slabels,
name="S"),
mxMatrix(
values=Fvalues,
free=FALSE,
dimnames=list(Fnamesx, Fnamesy),
name="F"),
mxMatrix(
free=t(Mfree),
values=t(Mvalues),
labels=t(Mlabels),
dimnames=list(1, Fnamesy),
name="M"),
############################################################
### different intervals for all timepoints (see delta_t) ###
############################################################
############### drift matrix (Alabels) ###############
mxAlgebra(vec2diag(eigenval(DRIFT)), name = "EVA"),
mxAlgebra(eigenvec(DRIFT), name = "EVEC"),
mxMatrix("Full", values=(matrix(1,n.latent,n.latent)-diag(n.latent)), name = "tempa"),
EXP_algebras <- mapply(EXP_Function, measurements, delta_t),		# see Algebra 1)
############### intercepts (Mlabels) ###############
int_algebras <- mapply(int_Function, measurements, delta_t),		# see Algebra 2)
############### Q matrix (Slabels)  ###############
mxAlgebra(DRIFT%x%II + II%x%DRIFT, name = "DRIFTHATCH"),
mxAlgebra(vec2diag(eigenval(DRIFTHATCH)), name = "EVAH"),
mxAlgebra(eigenvec(DRIFTHATCH), name = "EVECH"),
mxMatrix("Full", values=(matrix(1,n.latent**2,n.latent**2)-diag(n.latent**2)), name = "tempb"),
Qd_algebras <- mapply(Qd_Function,measurements,delta_t),			# see Algebra 3)
############### matrices in the model ###############
mxRAMObjective("A","S","F","M")
)
model2=mxModel(model,EXP_algebras,int_algebras,Qd_algebras)
return(model2)
}
#--- MODEL EVALUATION PIPELINE --------------------------------------------------------------------------------------------------------------------#
prepData <- function(df_long, manifestNames, timeVar="wave", minTpoints=2, exclWaves=NULL, keepOnlyWaves=NULL, exclNANs=FALSE, subj_types=c('anchor', 'partner'), genders=c(1,2), N_samples=NULL) {
# Keep only relevant subjects (parameter: subj_type)
df_long = df_long[df_long$subj_type %in% subj_types,]
df_long = df_long[df_long$sex %in% genders,]
# Exclude/Keep specifed waves from the dataset (parameters: exclWaves, keepWaves)
exclWaves = if(is.null(keepOnlyWaves)) exclWaves else setdiff(1:11, keepOnlyWaves)
for(exclWave in exclWaves) {
df_long = df_long[df_long$wave != exclWave,]
}
# Remove time points with only NANs for at least one variable (anchors and partners treated separately)
aggr = aggregate(df_long[,manifestNames], by=list(wave=df_long$wave, subj=df_long$subj_type), FUN=mean, na.rm=TRUE) # Mean variable values for each manifest variable per wave and subject (0=anchor; 1=partner) combination
emptyTpoints = aggr[rowSums(is.na(aggr[,manifestNames]))>0, c('wave')] # Waves without any data for at least one of the selected subj_type
for(emptyTpoint in emptyTpoints) {
df_long = df_long[df_long$wave!=emptyTpoint,]
}
# Remove rows with NANs, if specified (parameter: 'exclNANs')
if(exclNANs) {
df_long = df_long[complete.cases(df_long[,manifestNames]), ]
}
# Keep only subjects with data for at least minTpoints time points (parameter: minTpoints)
frequencies = data.frame(table(df_long['id']))
df_long = merge(x=df_long, y=frequencies, by.x="id", by.y='Var1', all.x = TRUE)
df_long = df_long[df_long[,'Freq']>=minTpoints,]
# Reduce sample size if required (parameter: 'sample_size')
ids = unique(df_long$id)
N_samples = if(is.null(N_samples) || N_samples>length(ids)) length(ids) else N_samples
ids = ids[sample(N_samples)] # Generate random sample of IDs
df_long = merge(x=df_long, y=ids, by.x='id', by.y=1, all.y=TRUE)
# Standardize variables
df_long[, manifestNames] = scale(df_long[, manifestNames])
# Transform & Intervalise long to wide data format
df_wide = reshape(df_long[,c('id', 'wave', manifestNames)], idvar="id", timevar="wave", sep=paste0("_T"), direction="wide") # Reshape long to wide format
rownames(df_wide) = df_wide$id # Set ID column as index
df_wide$id = NULL # Drop ID column
df_wide = df_wide[, order(as.integer(sub(".*_T", "", colnames(df_wide))))] # Reorder time points
colnames(df_wide) = paste0(sub("\\_.*", "", colnames(df_wide)), '_T', rep(0:ncol(df_wide), each=length(manifestNames), len=ncol(df_wide))) # Rename columns
delta_t = diff(sort(unique(df_long[,'wave'])))
df_intv = cbind(df_wide, matrix(delta_t, nrow=1, dimnames=list(c(),paste0('dT',(1:length(delta_t)))))) # Add time interval columns
# Print dataset characteristics
cat('Number of subjects:           ', nrow(df_intv), '\n')
cat('Average number of time points:', round(nrow(df_long)/nrow(df_intv),2), '\n')
cat('Mean interval:                ', round(mean(delta_t),2), '\n')
cat('Variance of time intervals:   ', round(var(delta_t),2), '\n')
cat('Percentage of NANs:           ', round(sum(is.na(df_long[,manifestNames]))/(nrow(df_long)*length(manifestNames))*100,1), '%\n')
return(df_intv)
}
build = function(data, manifestNames, Tpoints, type, hyperparams) {
if(type=='simple') {
mod = ''
for(var in manifestNames) {
for(T in 1:(Tpoints-1)) {
target = paste(var, T, sep='_T')
inputs = paste0(var, '_T', T-1)
if(sum(complete.cases(data[,c(target, inputs)])) > 0) { # Only add equations if at least 1 line with data for all involved variables
regr = paste0(target,' ~ ', paste0(paste0('auto_', var), ' * ', inputs))
intcp = paste0(target,' ~ intcp_',var,'*1')
mod = paste(mod, regr, intcp, sep=' \n ' )
}
}
}
return(mod)
}
else if(type=='lm' && Tpoints==2) {
mod = c()
for(var in manifestNames) {
mod = append(mod, as.formula(paste0(paste0(var,'_T1'), ' ~ ', paste(lapply(manifestNames, paste0, "_T0"), collapse=' + '))))
}
return(mod)
}
else if(type=='discrete') {
mod = ''
for(var in manifestNames) {
for(T in 1:(Tpoints-1)) {
target = paste(var, T, sep='_T')
inputs = paste0(manifestNames, '_T', T-1)
if(sum(complete.cases(data[,c(target, inputs)])) > 0) { # Only add equations if at least 1 line with data for all involved variables
regr = paste0(target,' ~ ',paste(paste0(var,'_',manifestNames, '*' ,inputs), collapse=' + '))
intcp = paste0(target,' ~ intcp_',var,'*1')
mod = paste(mod, regr, intcp, sep=' \n ' )
}
}
}
for(i in 1:length(manifestNames)) {
for(j in 1:length(manifestNames)) {
if(j>i) {
for(T in 1:(Tpoints-1)) {
var_i = paste0(manifestNames[i],'_T',T)
var_j = paste0(manifestNames[j],'_T',T)
if(grepl(paste(var_i,'~ '), mod, fixed=TRUE) && grepl(paste(var_j,'~ '), mod, fixed=TRUE)) { # Only add correlations for variables that have been defined as target earlier
mod = paste(mod, paste(paste(var_i,'~~',var_j), collapse= ' \n '), sep=' \n ')
}
}
}
}
}
return(mod)
}
else if(type=='stanct' || type=='omx') {
hyperparams$cint =          if (is.null(hyperparams$cint))             matrix(paste0("cint_",manifestNames),ncol=1)
else if (hyperparams$cint=='free')         matrix(paste0("cint_",manifestNames),ncol=1)
else if (hyperparams$cint=='zero')         'auto'
else                                       'auto'
hyperparams$manifestmeans = if(is.null(hyperparams$manifestmeans))     matrix(0, nrow=length(manifestNames), ncol=1)
else if(hyperparams$manifestmeans=='free') 'auto'
else if(hyperparams$manifestmeans=='zero') matrix(0, nrow=length(manifestNames), ncol=1)
else                                       matrix(0, nrow=length(manifestNames), ncol=1)
if(is.null(hyperparams$traitvar))  { hyperparams$traitvar=NULL }
mod = ctModel(type=type,
Tpoints=Tpoints,
n.manifest=length(manifestNames),
manifestNames=manifestNames,
MANIFESTMEANS = hyperparams$manifestmeans,
MANIFESTVAR = matrix(0, nrow=length(manifestNames), ncol=length(manifestNames)),
CINT = hyperparams$cint,
TRAITVAR = hyperparams$traitvar,
LAMBDA=diag(length(manifestNames)))
return(mod)
}
else { # The definition of the Voelkle model requires a data object. Therefore it is part of the 'fit' step
return(NULL)
}
}
fit = function(mod, data, manifestNames, type, hyperparams=list()) {
m = length(manifestNames)
if (type=='naive') {
estimates = matrix(cbind(diag(m), 0), nrow=m, dimnames=list(manifestNames, c(manifestNames, 'intcp')))
return(estimates)
}
if (type=='simple') {
if (is.null(hyperparams$missing)) { hyperparams$missing = 'listwise' }
fit = sem(mod, data=data, missing=hyperparams$missing)
coefs = coef(fit)[!duplicated(names(coef(fit)))]
estimates = matrix(cbind(diag(coefs[(1:m)*2-1]), coefs[(1:m)*2]), nrow=m, dimnames=list(manifestNames, c(manifestNames, 'intcp')))
return(estimates)
}
if (type=='discrete') {
if (is.null(hyperparams$missing)) { hyperparams$missing = 'listwise' }
fit = sem(mod, data=data, missing=hyperparams$missing, fixed.x=FALSE)
coefs = coef(fit)[!duplicated(names(coef(fit)))]
estimates = matrix(coefs[1:(m*(m+1))], nrow=m, byrow=TRUE, dimnames=list(manifestNames, c(manifestNames, 'intcp')))
return(estimates)
}
else if (type=='lm') {
estimates = matrix(nrow=0, ncol=m+1, dimnames=list(c(), c(manifestNames, 'intcp')))
for(i in 1:m) {
fit = lm(mod[[i]], data=data)
estimates = rbind(estimates, matrix(c(fit$coefficients[c(2:(m+1),1)]), nrow=1, dimnames=list(manifestNames[i], c())))
}
return(estimates)
}
else if (type=='omx') {
retryattempts = if (is.null(hyperparams$retryattempts)) 10 else hyperparams$retryattempts
if(is.null(hyperparams$carefulFit)) { hyperparams$carefulFit=TRUE }
set.seed(42)
fit = ctFit(ctmodelobj=mod, dat=data, dataform="wide", carefulFit=hyperparams$carefulFit, retryattempts=retryattempts)
res = summary(fit)
estimates = matrix(cbind(res$DRIFT, res$CINT, res$MANIFESTMEANS), nrow=m, dimnames=list(manifestNames, c(manifestNames, 'intcp', 'mmeans')))
return(estimates)
}
else if (type=='stanct') {
set.seed(42)
fit = ctStanFit(datalong=data, ctstanmodel=mod, cores=6, verbose=1)
}
else if (type=='voelkle') {
m = length(manifestNames)
l = m #  number of latentvariables
Tpoints = (ncol(data)+1)/(length(manifestNames)+1)
intvls = as.vector(as.matrix(data[1,(m*Tpoints+1):ncol(data)]))
mean_dt = mean(intvls)
retryattempts = if (is.null(hyperparams$retryattempts)) 10 else hyperparams$retryattempts
# Obtain starting values for parameters from discrete model
mod_disc = build(data, manifestNames, Tpoints, type='discrete')
startVals = fit(mod_disc, data, manifestNames, type='discrete', hyperparams=list(missing='fiml'))
A_disc = startVals[,1:m]
b_disc = startVals[,m+1]
predictions_disc = pred(startVals, data, type='discrete')
errCov_disc = rmse(predictions_disc, data, manifestNames, getErrCov=TRUE)
A_cont = logm(A_disc)/ (if(hyperparams$approx == 'unitIntv') 1 else mean_dt)
b_cont = solve(A_disc-diag(l)) %*% A_cont %*% b_disc
A_hash = A_cont %x% diag(l) + diag(l) %x% A_cont
Q_cont = matrix(solve(solve(A_hash) %*% (expm(A_hash*mean_dt) - diag(l*l))) %*% c(errCov_disc), nrow=l, ncol=l)
A_cont[A_cont == 0] = 0.01
b_cont[b_cont == 0] = 0.01
A_cont[A_cont == 1] = 0.99
b_cont[b_cont == 1] = 0.99
mod = voelkleModel(n.manifest   = m,                                                                       # total number of indicators for ALL factors.
n.latent     = l,                                                                       # number of latent variables
PHI1         = cov(data[,paste0(manifestNames, '_T0')], use = "pairwise.complete.obs"), # var/cov matrix of latent variables at first time point
latentM1     = matrix(colMeans(data[,paste0(manifestNames, '_T0')], na.rm=TRUE), nrow=l, ncol=1),   # means of latent variables at first time point
manifestM    = matrix(0, nrow=m, ncol=1, byrow=TRUE),                                   # intercepts of manifest variables (usually fixed to zero)
LAMBDA       = matrix(diag(1, m), nrow=m, ncol=l,byrow=TRUE),                           # factor loading matrix
THETA        = matrix(0,nrow=m, ncol=m),                                                # var/cov matrix of measurement error
DRIFT        = A_cont,                                                         # crude approximation of drift matrix
CINT         = matrix(b_cont, ncol=l, nrow=1, byrow=TRUE),                     # continuous time intercepts
Q            = round(Q_cont,4),                                                         # diffusion matrix
delta_t      = intvls,                                                                  # vector of (possibly different) time intervals
data         = data[,(1:(m*Tpoints))],
Tpoints      = Tpoints,
measurements = 1:(Tpoints-1))
# Fit the model
fit_voelkle = mxTryHard(mod, extraTries = retryattempts, scale=0.1)
summary = summary(fit_voelkle)$parameters[,c('name', 'matrix', 'Estimate')]
A_cont = matrix(summary[summary[,'matrix']=='DRIFT', 'Estimate'], ncol=m)
b_cont = matrix(summary[summary[,'matrix']=='CINT', 'Estimate'], ncol=1)
estimates = matrix(cbind(A_cont, b_cont), nrow=m, dimnames=list(manifestNames, c(manifestNames, 'intcp')))
return(estimates)
}
}
contToDisc <- function(A_cont=NULL, b_cont=NULL, b_disc=NULL, manifestNames=NULL, estimates=NULL, interval=1) {
manifestNames= if(is.null(manifestNames)) rownames(estimates) else manifestNames
m = length(manifestNames)
A_cont = if(is.null(A_cont)) estimates[,(1:m)] else A_cont
b_cont = if(is.null(b_cont)) estimates[,m+1] else b_cont
b_disc = if(ncol(estimates)>m+1) estimates[,m+2] else if(!is.null(b_disc)) b_disc else numeric(m)
A_disc = expm(A_cont*interval)
b_disc = solve(A_cont) %*% (A_disc-diag(1,m)) %*% b_cont + b_disc
estimates = matrix(cbind(A_disc, b_disc), nrow=m, dimnames=list(manifestNames, c(manifestNames, 'intcp')))
return(estimates)
}
pred = function(estimates, data, type) {
manifestNames = rownames(estimates)
Tpoints = ceiling(ncol(data)/(length(manifestNames)+1))
predictions = data.frame(matrix(nrow=nrow(data), ncol=0))
# Predictions dependent on time interval
if(type=='stanct' || type=='omx' || type=='voelkle') {
# Derive dicrete drift matrixes for all possible time intervals
intervals = unique(as.vector(as.matrix(data[,(ncol(data)-Tpoints+2):ncol(data)])))
estimates_disc = matrix(ncol=length(manifestNames)+1+1, nrow=0)
for(interval in intervals) {
estimate_disc = contToDisc(estimates=estimates, interval=interval)
estimates_disc = rbind(estimates_disc, cbind(interval=interval, estimate_disc))
}
# Make predictions
for (T in 1:(Tpoints-1)) {
for (var in manifestNames) {
rel_cols = cbind(data.matrix(data[,c(paste0('dT',T),paste0(manifestNames, '_T', T-1))]), 1)
prediction = c()
for (i in 1:nrow(rel_cols)) {
val = rel_cols[i,-1]
est = estimates_disc[(estimates_disc[,'interval']==rel_cols[i,1]) & (rownames(estimates_disc)==var), -1]
prediction = rbind(prediction, val %*% est)
}
predictions[paste0(var,'_T',T)] = prediction
}
}
}
# Predictions independent of time interval
else {
for (T in 1:(Tpoints-1)) {
for (var in manifestNames) {
rel_cols = cbind(data.matrix(data[,paste0(manifestNames, '_T', T-1)]), 1)
prediction = (rel_cols %*% estimates[var,])
predictions[paste0(var,'_T',T)] = prediction
}
}
}
return(predictions)
}
rmse = function(predictions, data, manifestNames, getErrCov=FALSE) {
residuals_all = matrix(ncol=0, nrow=nrow(data))
for (var in manifestNames) {
residuals_var = c()
Tpoints = ceiling(ncol(data)/(length(manifestNames)+1))
for (T in 1:(Tpoints-1)) {
col = paste0(var,'_T',T)
residuals = data[col] - predictions[col]
residuals = residuals[complete.cases(residuals),]
residuals_var = c(residuals_var, residuals)
}
residuals_all = cbind(residuals_all, residuals_var)
}
if(getErrCov) {
return(var(residuals_all))
}
else {
return(sqrt(colMeans(residuals_all^2)))
}
}
evaluate = function(mod, dat.train, dat.val, manifestNames, mod_type, hyperparams=list()) {
# Fit the model
start_time = Sys.time()
estimates = fit(mod, dat.train, manifestNames, mod_type, hyperparams)
end_time = Sys.time()
secs = difftime(end_time, start_time, units = "secs")[[1]]
# Evaluate model on training and validation data
pred_train = pred(estimates, dat.train, mod_type)
rmse_train = rmse(pred_train, dat.train, manifestNames)
if(!is.null(dat.val)) {
pred_val = pred(estimates, dat.val, mod_type)
rmse_val = rmse(pred_val, dat.val, manifestNames)
}
else { rmse_val = NA }
# Wrap results for continuous time models
res = data.frame()
if (mod_type=='omx' || mod_type=='stanct' || mod_type=='voelkle') {
res = rbind.fill(res, data.frame(paramType='cont', target=rownames(estimates),
estimates, secs=secs, rmse_train=rmse_train, rmse_val=rmse_val))
Tpoints = (ncol(dat.train)+1)/(length(manifestNames)+1)
intervals = c(as.matrix(dat.train[,(length(manifestNames)*Tpoints+1):ncol(dat.train)]))
delta_t = mean(intervals[intervals>=1])
estimates_disc = contToDisc(estimates=estimates, interval=delta_t)
res = rbind.fill(res, data.frame(paramType='disc', target=rownames(estimates_disc),
secs=secs, estimates_disc, rmse_train=rmse_train, rmse_val=rmse_val))
}
# Wrap results for discrete time models
else {
res = rbind.fill(res, data.frame(paramType='disc', target=rownames(estimates),
estimates, secs=secs, rmse_train=rmse_train, rmse_val=rmse_val))
}
return(res)
}
cv = function(mod, dat, manifestNames, mod_type, hyperparams=list(), k=NULL) {
set.seed(42)
folds = cut(seq(1, nrow(dat)), breaks=k, labels=FALSE) # Create equally size folds
res = data.frame()
for(fold in 1:k){
# Separate train and validation set
set.seed(42)
sample = which(folds!=fold, arr.ind=TRUE)
dat.train = dat[sample, ]
dat.val   = dat[-sample, ]
# Evaluate model
res_fold = evaluate(mod, dat.train, dat.val, manifestNames, mod_type, hyperparams=hyperparams)
res_fold['fold'] = fold
res = rbind.fill(res, res_fold)
print(res_fold)
}
return(res)
}
modEval = function(dat.trainVal, manifestNames, mod_type, hyperparams=list(), k=NULL, val_size=NULL, dat.test=NULL, final_fit=FALSE) {
# Build model
Tpoints = ceiling(ncol(dat.trainVal)/(length(manifestNames)+1))
mod = build(dat.trainVal, manifestNames, Tpoints, mod_type, hyperparams)
res = data.frame()
# Cross validation, if requested through parameter k
if(!is.null(k)) {
res_cv = cv(mod, dat.trainVal, manifestNames, mod_type, hyperparams, k=k)
res_cv['data_train'] = 'train'
res = rbind.fill(res, res_cv)
}
# Ordinary performance evaluation, if no cross validation, but specified val_size
else if(!is.null(val_size)) {
dat.subsets = trainTestSplit(dat.trainVal, val_size)
dat.train = dat.subsets['train']
dat.val = dat.subsets['test']
res_val = evaluate(mod, dat.train, dat.val, manifestNames, mod_type, hyperparams)
res_cv['data_train'] = 'train'
res = rbind.fill(res, res_test)
}
# Evaluate performance on test data using training and validation data combined
else if(!is.null(dat.test)) {
res_test = evaluate(mod, dat.trainVal, dat.test, manifestNames, mod_type, hyperparams)
res_test['data_train'] = 'trainVal'
res = rbind.fill(res, res_test)
}
# Final fit with complete dataset
if(final_fit || (is.null(k) & is.null(val_size) & is.null(dat.test))) {
res_final = evaluate(mod, dat.trainVal, NULL, manifestNames, mod_type, hyperparams)
res_final['data_train'] = 'trainValTest'
res = rbind.fill(res, res_final)
}
return(res)
}
modComp = function(models, dat.trainVal, manifestNames, mode='normal', k=NULL, val_size=NULL, data.test=NULL) {
# Deactivate linear model if Tpoints > 2
if(ncol(dat.trainVal) != ((length(manifestNames)+1)*2)-1) { models = models[names(models)!='lm'] }
res = data.frame()
for (i in (1:length(models))) {
mod_id = sort(names(models))[i]
mod_type = if(is.null(models[[mod_id]]$type)) mod_id else models[[mod_id]]$type
cat('Model ', mod_id, 'build & evaluation begins\n')
res_mod = modEval(dat.trainVal, manifestNames, mod_type, hyperparams=models[[mod_id]], k=k, val_size=val_size)
res = rbind.fill(res, cbind(model=mod_id, res_mod))
cat('Model ', mod_id, 'build & evaluation complete\n')
}
printRes(res)
return(res)
}
trainTestSplit = function(dat, test_size) {
set.seed(42)
sample = sample.int(n=nrow(dat), size=floor((1-test_size)*nrow(dat)))
dat.train = dat[sample, ]
dat.test = dat[-sample, ]
return(list(train=dat.train, test=dat.test))
}
printRes = function(res, paramType='disc', sortby='rmse_val') {
res = res[res$paramType==paramType,]
# Aggregate results from CV
non_numeric_cols = c("model", "data_train", "paramType", "fold", "target")
res.agg = aggregate(res[, !names(res) %in% non_numeric_cols],
by=list(model=res$model, data_train=res$data_train, target=res$target, paramType=res$paramType), FUN=mean)
# Round values to 3 decimals
res.agg[, !names(res.agg) %in% non_numeric_cols] = round(res.agg[, !names(res.agg) %in% non_numeric_cols], 4)
# Output
options(scipen = 50)
print(res.agg[order(res.agg$target, res.agg[sortby]),])
}
writeRes = function(resNames=NULL) {
if(is.null(resNames)) { resNames=ls(envir=.GlobalEnv, pat='res') }
for(resName in resNames) {
write.csv(get(resName), paste0('../../results/', resName, '.csv'))
}
}
readRes = function(resNames=NULL) {
if(is.null(resNames)) { resNames=sub('.csv', '', list.files(path='../../results/', pattern='res')) }
for(resName in resNames) {
assign(resName, read.csv(paste0('../../results/', resName, '.csv')), envir=.GlobalEnv)
}
}
readRes()
printRes(res1b)
printRes(res2b)
readRes()
# PREREQUISITES
setwd("C:/Users/schneluc/OneDrive - adidas/5. Master Program/5. Masterarbeit/implementation/RStudio")
readRes()
printRes(res2b)
printRes(res1b)
printRes(res3b)
printRes(res1a)
printRes(res2a)
printRes(res3a)
